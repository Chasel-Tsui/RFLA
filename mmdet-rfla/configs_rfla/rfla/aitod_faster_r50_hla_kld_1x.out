/home/xc/RFLA/mmdet-rfla/mmdet/utils/setup_env.py:39: UserWarning: Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting OMP_NUM_THREADS environment variable for each process '
/home/xc/RFLA/mmdet-rfla/mmdet/utils/setup_env.py:49: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  f'Setting MKL_NUM_THREADS environment variable for each process '
2022-07-08 10:12:14,799 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
CUDA available: True
GPU 0: GeForce RTX 3090
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.105
GCC: gcc (Ubuntu 6.5.0-2ubuntu1~16.04) 6.5.0 20181026
PyTorch: 1.10.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0
OpenCV: 4.6.0
MMCV: 1.5.3
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMDetection: 2.24.1+b9624df
------------------------------------------------------------

2022-07-08 10:12:15,056 - mmdet - INFO - Distributed training: False
2022-07-08 10:12:15,264 - mmdet - INFO - Config:
dataset_type = 'AITODDataset'
data_root = 'data/AI-TOD/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(800, 800), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(800, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='AITODDataset',
        ann_file='data/AI-TOD/annotations/small_trainval_v1_1.0.json',
        img_prefix='data/AI-TOD/trainval/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(800, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='AITODDataset',
        ann_file='data/AI-TOD/annotations/small_test_v1_1.0.json',
        img_prefix='data/AI-TOD/test/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(800, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='AITODDataset',
        ann_file='data/AI-TOD/annotations/small_test_v1_1.0.json',
        img_prefix='data/AI-TOD/test/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(800, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=12, metric='bbox')
optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=5000,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=4)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
model = dict(
    type='FasterRCNN',
    pretrained='torchvision://resnet50',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[4],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=8,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='HieAssigner',
                ignore_iof_thr=-1,
                gpu_assign_thr=512,
                iou_calculator=dict(type='BboxDistanceMetric'),
                assign_metric='kld',
                topk=[3, 1],
                ratio=0.9),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=3000,
            max_per_img=3000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=False,
                ignore_iof_thr=-1,
                gpu_assign_thr=512),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=3000,
            max_per_img=3000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=3000)))
fp16 = dict(loss_scale=512.0)
work_dir = './work_dirs/aitod_faster_r50_hla_kld_1x'
auto_resume = False
gpu_ids = [0]

2022-07-08 10:12:15,264 - mmdet - INFO - Set random seed to 2084638057, deterministic: False
/home/xc/RFLA/mmdet-rfla/mmdet/models/detectors/two_stage.py:29: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
/home/xc/RFLA/mmdet-rfla/mmdet/models/backbones/resnet.py:401: UserWarning: DeprecationWarning: pretrained is deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is deprecated, '
2022-07-08 10:12:15,582 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
2022-07-08 10:12:15,582 - mmcv - INFO - load model from: torchvision://resnet50
2022-07-08 10:12:15,582 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50
2022-07-08 10:12:15,654 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2022-07-08 10:12:15,670 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2022-07-08 10:12:15,690 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2022-07-08 10:12:15,694 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
2022-07-08 10:12:21,022 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2022-07-08 10:12:24,056 - mmdet - INFO - Start running, host: xc@amazon-Z370-HD3, work_dir: /home/xc/RFLA/mmdet-rfla/work_dirs/aitod_faster_r50_hla_kld_1x
2022-07-08 10:12:24,056 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) Fp16OptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2022-07-08 10:12:24,056 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2022-07-08 10:12:24,057 - mmdet - INFO - Checkpoints will be saved to /home/xc/RFLA/mmdet-rfla/work_dirs/aitod_faster_r50_hla_kld_1x by HardDiskBackend.
loading annotations into memory...
Done (t=2.21s)
creating index...
index created!
loading annotations into memory...
Done (t=2.73s)
creating index...
index created!
2022-07-08 10:12:34,712 - mmdet - INFO - Epoch [1][50/7009]	lr: 5.395e-05, eta: 4:58:27, time: 0.213, data_time: 0.049, memory: 3272, loss_rpn_cls: 0.6914, loss_rpn_bbox: 0.1336, loss_cls: 0.9666, acc: 85.9395, loss_bbox: 0.0297, loss: 1.8213
2022-07-08 10:12:41,767 - mmdet - INFO - Epoch [1][100/7009]	lr: 1.039e-04, eta: 4:07:55, time: 0.141, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.6541, loss_rpn_bbox: 0.1334, loss_cls: 0.2740, acc: 95.8613, loss_bbox: 0.0227, loss: 1.0842
2022-07-08 10:12:48,645 - mmdet - INFO - Epoch [1][150/7009]	lr: 1.539e-04, eta: 3:49:20, time: 0.138, data_time: 0.003, memory: 5879, loss_rpn_cls: 0.4780, loss_rpn_bbox: 0.1501, loss_cls: 0.2528, acc: 95.1953, loss_bbox: 0.0177, loss: 0.8986
2022-07-08 10:13:00,263 - mmdet - INFO - Epoch [1][200/7009]	lr: 2.038e-04, eta: 4:13:08, time: 0.232, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.2867, loss_rpn_bbox: 0.1052, loss_cls: 0.1625, acc: 96.4102, loss_bbox: 0.0277, loss: 0.5821
2022-07-08 10:13:16,853 - mmdet - INFO - Epoch [1][250/7009]	lr: 2.538e-04, eta: 4:55:08, time: 0.332, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.2756, loss_rpn_bbox: 0.1205, loss_cls: 0.2239, acc: 94.9355, loss_bbox: 0.0793, loss: 0.6992
2022-07-08 10:13:23,289 - mmdet - INFO - Epoch [1][300/7009]	lr: 3.037e-04, eta: 4:35:45, time: 0.129, data_time: 0.003, memory: 5879, loss_rpn_cls: 0.2722, loss_rpn_bbox: 0.1394, loss_cls: 0.2764, acc: 93.4180, loss_bbox: 0.1414, loss: 0.8294
2022-07-08 10:13:29,671 - mmdet - INFO - Epoch [1][350/7009]	lr: 3.537e-04, eta: 4:21:41, time: 0.128, data_time: 0.003, memory: 5879, loss_rpn_cls: 0.1895, loss_rpn_bbox: 0.1100, loss_cls: 0.1825, acc: 94.6113, loss_bbox: 0.1128, loss: 0.5947
2022-07-08 10:13:37,426 - mmdet - INFO - Epoch [1][400/7009]	lr: 4.036e-04, eta: 4:15:52, time: 0.155, data_time: 0.005, memory: 5879, loss_rpn_cls: 0.2303, loss_rpn_bbox: 0.1460, loss_cls: 0.2553, acc: 92.4785, loss_bbox: 0.1797, loss: 0.8114
2022-07-08 10:13:44,391 - mmdet - INFO - Epoch [1][450/7009]	lr: 4.536e-04, eta: 4:08:53, time: 0.139, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.2004, loss_rpn_bbox: 0.1245, loss_cls: 0.2244, acc: 93.0625, loss_bbox: 0.1749, loss: 0.7243
2022-07-08 10:13:51,384 - mmdet - INFO - Epoch [1][500/7009]	lr: 5.035e-04, eta: 4:03:21, time: 0.140, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.2193, loss_rpn_bbox: 0.1368, loss_cls: 0.2287, acc: 92.1680, loss_bbox: 0.2002, loss: 0.7850
2022-07-08 10:13:57,749 - mmdet - INFO - Epoch [1][550/7009]	lr: 5.535e-04, eta: 3:57:13, time: 0.127, data_time: 0.003, memory: 5879, loss_rpn_cls: 0.2126, loss_rpn_bbox: 0.1268, loss_cls: 0.2222, acc: 93.1660, loss_bbox: 0.1893, loss: 0.7509
2022-07-08 10:14:05,295 - mmdet - INFO - Epoch [1][600/7009]	lr: 6.034e-04, eta: 3:54:49, time: 0.151, data_time: 0.005, memory: 5879, loss_rpn_cls: 0.1348, loss_rpn_bbox: 0.1155, loss_cls: 0.2084, acc: 93.1367, loss_bbox: 0.1924, loss: 0.6511
2022-07-08 10:14:12,198 - mmdet - INFO - Epoch [1][650/7009]	lr: 6.534e-04, eta: 3:51:24, time: 0.138, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.1150, loss_rpn_bbox: 0.0958, loss_cls: 0.1960, acc: 94.2598, loss_bbox: 0.1742, loss: 0.5811
2022-07-08 10:14:20,057 - mmdet - INFO - Epoch [1][700/7009]	lr: 7.033e-04, eta: 3:50:21, time: 0.157, data_time: 0.005, memory: 5879, loss_rpn_cls: 0.1353, loss_rpn_bbox: 0.1162, loss_cls: 0.2087, acc: 93.3164, loss_bbox: 0.1909, loss: 0.6512
2022-07-08 10:14:28,460 - mmdet - INFO - Epoch [1][750/7009]	lr: 7.533e-04, eta: 3:50:25, time: 0.168, data_time: 0.006, memory: 5879, loss_rpn_cls: 0.1457, loss_rpn_bbox: 0.1144, loss_cls: 0.2421, acc: 92.5039, loss_bbox: 0.2181, loss: 0.7202
2022-07-08 10:14:51,073 - mmdet - INFO - Epoch [1][800/7009]	lr: 8.032e-04, eta: 4:15:08, time: 0.452, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.1259, loss_rpn_bbox: 0.1169, loss_cls: 0.2096, acc: 92.9141, loss_bbox: 0.1957, loss: 0.6481
2022-07-08 10:14:58,964 - mmdet - INFO - Epoch [1][850/7009]	lr: 8.532e-04, eta: 4:12:52, time: 0.158, data_time: 0.005, memory: 5879, loss_rpn_cls: 0.1194, loss_rpn_bbox: 0.1182, loss_cls: 0.2135, acc: 92.8398, loss_bbox: 0.2221, loss: 0.6732
2022-07-08 10:15:25,785 - mmdet - INFO - Epoch [1][900/7009]	lr: 9.031e-04, eta: 4:40:00, time: 0.536, data_time: 0.005, memory: 5879, loss_rpn_cls: 0.1169, loss_rpn_bbox: 0.1242, loss_cls: 0.2208, acc: 92.4316, loss_bbox: 0.2570, loss: 0.7189
2022-07-08 10:15:32,711 - mmdet - INFO - Epoch [1][950/7009]	lr: 9.531e-04, eta: 4:35:13, time: 0.138, data_time: 0.004, memory: 5879, loss_rpn_cls: 0.1175, loss_rpn_bbox: 0.1010, loss_cls: 0.2023, acc: 93.6914, loss_bbox: 0.1869, loss: 0.6077
2022-07-08 10:15:39,846 - mmdet - INFO - Exp name: aitod_faster_r50_hla_kld_1x.py
2022-07-08 10:15:39,847 - mmdet - INFO - Epoch [1][1000/7009]	lr: 1.003e-03, eta: 4:31:11, time: 0.143, data_time: 0.004, memory: 6182, loss_rpn_cls: 0.1393, loss_rpn_bbox: 0.1289, loss_cls: 0.2428, acc: 91.9961, loss_bbox: 0.2550, loss: 0.7661
2022-07-08 10:15:46,890 - mmdet - INFO - Epoch [1][1050/7009]	lr: 1.053e-03, eta: 4:27:24, time: 0.141, data_time: 0.004, memory: 6182, loss_rpn_cls: 0.1603, loss_rpn_bbox: 0.1174, loss_cls: 0.2661, acc: 91.1680, loss_bbox: 0.2608, loss: 0.8046
2022-07-08 10:15:55,922 - mmdet - INFO - Epoch [1][1100/7009]	lr: 1.103e-03, eta: 4:26:27, time: 0.181, data_time: 0.006, memory: 6182, loss_rpn_cls: 0.1485, loss_rpn_bbox: 0.1435, loss_cls: 0.2937, acc: 90.9023, loss_bbox: 0.2793, loss: 0.8649
2022-07-08 10:16:09,745 - mmdet - INFO - Epoch [1][1150/7009]	lr: 1.153e-03, eta: 4:31:19, time: 0.276, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0854, loss_rpn_bbox: 0.0871, loss_cls: 0.1818, acc: 94.0020, loss_bbox: 0.2234, loss: 0.5776
2022-07-08 10:16:16,768 - mmdet - INFO - Epoch [1][1200/7009]	lr: 1.203e-03, eta: 4:27:57, time: 0.140, data_time: 0.004, memory: 6182, loss_rpn_cls: 0.1069, loss_rpn_bbox: 0.1341, loss_cls: 0.2693, acc: 90.6523, loss_bbox: 0.3277, loss: 0.8379
2022-07-08 10:16:23,915 - mmdet - INFO - Epoch [1][1250/7009]	lr: 1.253e-03, eta: 4:24:58, time: 0.143, data_time: 0.004, memory: 6182, loss_rpn_cls: 0.1005, loss_rpn_bbox: 0.1359, loss_cls: 0.2364, acc: 91.6660, loss_bbox: 0.2965, loss: 0.7692
2022-07-08 10:16:33,463 - mmdet - INFO - Epoch [1][1300/7009]	lr: 1.303e-03, eta: 4:24:46, time: 0.191, data_time: 0.006, memory: 6182, loss_rpn_cls: 0.0898, loss_rpn_bbox: 0.1312, loss_cls: 0.2438, acc: 91.2891, loss_bbox: 0.2980, loss: 0.7629
2022-07-08 10:16:49,407 - mmdet - INFO - Epoch [1][1350/7009]	lr: 1.353e-03, eta: 4:31:05, time: 0.319, data_time: 0.007, memory: 6182, loss_rpn_cls: 0.0911, loss_rpn_bbox: 0.1239, loss_cls: 0.2188, acc: 91.6484, loss_bbox: 0.3159, loss: 0.7497
2022-07-08 10:16:57,180 - mmdet - INFO - Epoch [1][1400/7009]	lr: 1.403e-03, eta: 4:28:54, time: 0.155, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0704, loss_rpn_bbox: 0.0993, loss_cls: 0.1887, acc: 93.1543, loss_bbox: 0.2654, loss: 0.6238
2022-07-08 10:17:05,395 - mmdet - INFO - Epoch [1][1450/7009]	lr: 1.453e-03, eta: 4:27:17, time: 0.164, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0863, loss_rpn_bbox: 0.1299, loss_cls: 0.2289, acc: 90.9531, loss_bbox: 0.2957, loss: 0.7408
2022-07-08 10:17:13,058 - mmdet - INFO - Epoch [1][1500/7009]	lr: 1.503e-03, eta: 4:25:15, time: 0.153, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0763, loss_rpn_bbox: 0.0987, loss_cls: 0.1775, acc: 93.2793, loss_bbox: 0.2350, loss: 0.5875
2022-07-08 10:17:30,968 - mmdet - INFO - Epoch [1][1550/7009]	lr: 1.552e-03, eta: 4:32:26, time: 0.358, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0966, loss_rpn_bbox: 0.1040, loss_cls: 0.2311, acc: 91.6719, loss_bbox: 0.2885, loss: 0.7202
2022-07-08 10:17:38,687 - mmdet - INFO - Epoch [1][1600/7009]	lr: 1.602e-03, eta: 4:30:24, time: 0.154, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0773, loss_rpn_bbox: 0.0941, loss_cls: 0.1806, acc: 93.6387, loss_bbox: 0.2599, loss: 0.6119
2022-07-08 10:17:46,284 - mmdet - INFO - Epoch [1][1650/7009]	lr: 1.652e-03, eta: 4:28:22, time: 0.152, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0746, loss_rpn_bbox: 0.0855, loss_cls: 0.1980, acc: 93.4551, loss_bbox: 0.2251, loss: 0.5832
2022-07-08 10:17:54,232 - mmdet - INFO - Epoch [1][1700/7009]	lr: 1.702e-03, eta: 4:26:44, time: 0.159, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0920, loss_rpn_bbox: 0.1247, loss_cls: 0.2278, acc: 90.9902, loss_bbox: 0.3239, loss: 0.7684
2022-07-08 10:18:02,025 - mmdet - INFO - Epoch [1][1750/7009]	lr: 1.752e-03, eta: 4:25:04, time: 0.156, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0815, loss_rpn_bbox: 0.0926, loss_cls: 0.1953, acc: 92.8594, loss_bbox: 0.2590, loss: 0.6283
2022-07-08 10:18:09,898 - mmdet - INFO - Epoch [1][1800/7009]	lr: 1.802e-03, eta: 4:23:33, time: 0.157, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0813, loss_rpn_bbox: 0.0992, loss_cls: 0.2003, acc: 92.9551, loss_bbox: 0.2380, loss: 0.6188
2022-07-08 10:18:26,551 - mmdet - INFO - Epoch [1][1850/7009]	lr: 1.852e-03, eta: 4:28:37, time: 0.333, data_time: 0.006, memory: 6182, loss_rpn_cls: 0.1187, loss_rpn_bbox: 0.1411, loss_cls: 0.2504, acc: 90.9590, loss_bbox: 0.3232, loss: 0.8333
2022-07-08 10:18:39,890 - mmdet - INFO - Epoch [1][1900/7009]	lr: 1.902e-03, eta: 4:31:00, time: 0.267, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.1197, loss_rpn_bbox: 0.1458, loss_cls: 0.2750, acc: 89.9883, loss_bbox: 0.3405, loss: 0.8811
2022-07-08 10:18:47,571 - mmdet - INFO - Epoch [1][1950/7009]	lr: 1.952e-03, eta: 4:29:17, time: 0.154, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0906, loss_rpn_bbox: 0.1097, loss_cls: 0.2111, acc: 92.8027, loss_bbox: 0.2715, loss: 0.6830
2022-07-08 10:18:55,610 - mmdet - INFO - Exp name: aitod_faster_r50_hla_kld_1x.py
2022-07-08 10:18:55,610 - mmdet - INFO - Epoch [1][2000/7009]	lr: 2.002e-03, eta: 4:27:54, time: 0.161, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0662, loss_rpn_bbox: 0.0759, loss_cls: 0.1686, acc: 93.8984, loss_bbox: 0.2190, loss: 0.5297
2022-07-08 10:19:05,827 - mmdet - INFO - Epoch [1][2050/7009]	lr: 2.052e-03, eta: 4:28:01, time: 0.204, data_time: 0.007, memory: 6182, loss_rpn_cls: 0.0749, loss_rpn_bbox: 0.1033, loss_cls: 0.1805, acc: 92.9922, loss_bbox: 0.2465, loss: 0.6052
2022-07-08 10:19:14,991 - mmdet - INFO - Epoch [1][2100/7009]	lr: 2.102e-03, eta: 4:27:26, time: 0.183, data_time: 0.006, memory: 6182, loss_rpn_cls: 0.0792, loss_rpn_bbox: 0.1183, loss_cls: 0.2202, acc: 91.9453, loss_bbox: 0.2772, loss: 0.6949
2022-07-08 10:19:23,429 - mmdet - INFO - Epoch [1][2150/7009]	lr: 2.152e-03, eta: 4:26:25, time: 0.169, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0850, loss_rpn_bbox: 0.1084, loss_cls: 0.2572, acc: 90.9082, loss_bbox: 0.3004, loss: 0.7509
2022-07-08 10:19:31,580 - mmdet - INFO - Epoch [1][2200/7009]	lr: 2.202e-03, eta: 4:25:16, time: 0.163, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0845, loss_rpn_bbox: 0.0997, loss_cls: 0.1977, acc: 92.1562, loss_bbox: 0.2775, loss: 0.6594
2022-07-08 10:19:45,175 - mmdet - INFO - Epoch [1][2250/7009]	lr: 2.252e-03, eta: 4:27:27, time: 0.272, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0867, loss_rpn_bbox: 0.1120, loss_cls: 0.2286, acc: 91.3340, loss_bbox: 0.2828, loss: 0.7101
2022-07-08 10:19:55,957 - mmdet - INFO - Epoch [1][2300/7009]	lr: 2.302e-03, eta: 4:27:52, time: 0.216, data_time: 0.007, memory: 6182, loss_rpn_cls: 0.0830, loss_rpn_bbox: 0.1039, loss_cls: 0.2145, acc: 92.1953, loss_bbox: 0.2631, loss: 0.6644
2022-07-08 10:20:05,055 - mmdet - INFO - Epoch [1][2350/7009]	lr: 2.352e-03, eta: 4:27:17, time: 0.182, data_time: 0.006, memory: 6182, loss_rpn_cls: 0.0889, loss_rpn_bbox: 0.1209, loss_cls: 0.2185, acc: 91.1426, loss_bbox: 0.3160, loss: 0.7443
2022-07-08 10:20:12,708 - mmdet - INFO - Epoch [1][2400/7009]	lr: 2.402e-03, eta: 4:25:54, time: 0.153, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0767, loss_rpn_bbox: 0.0953, loss_cls: 0.1965, acc: 92.6562, loss_bbox: 0.2747, loss: 0.6432
2022-07-08 10:20:28,899 - mmdet - INFO - Epoch [1][2450/7009]	lr: 2.452e-03, eta: 4:29:19, time: 0.324, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0754, loss_rpn_bbox: 0.1153, loss_cls: 0.2168, acc: 91.6816, loss_bbox: 0.2972, loss: 0.7048
2022-07-08 10:20:37,080 - mmdet - INFO - Epoch [1][2500/7009]	lr: 2.502e-03, eta: 4:28:13, time: 0.164, data_time: 0.005, memory: 6182, loss_rpn_cls: 0.0839, loss_rpn_bbox: 0.1151, loss_cls: 0.2183, acc: 91.9531, loss_bbox: 0.2972, loss: 0.7144
